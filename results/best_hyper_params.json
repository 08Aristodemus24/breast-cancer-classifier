{"layer_1": 901, "layer_2": 501, "layer_3": 201, "layer_4": 401, "layer_5": 701, "layer_6": 601, "activation": "tanh", "learning_rate": 1.2, "lambda": 0.9, "optimizer": "Adadelta", "dropout": 0.1, "initializer": "HeUniform", "layer_num": 6}